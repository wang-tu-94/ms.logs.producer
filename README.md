# üì° MS Logs Producer (gRPC & Kafka)

<div align="center">
  <img src="https://img.shields.io/badge/Java_21-%23ED8B00.svg?style=for-the-badge&logo=openjdk&logoColor=white" alt="Java 21" />
  <img src="https://img.shields.io/badge/Spring_Boot-F2F4F9?style=for-the-badge&logo=spring-boot" alt="Spring Boot" />
  <img src="https://img.shields.io/badge/gRPC-244C5A?style=for-the-badge&logo=gRPC&logoColor=white" alt="gRPC" />
  <img src="https://img.shields.io/badge/Apache_Kafka-231F20?style=for-the-badge&logo=apache-kafka&logoColor=white" alt="Apache Kafka" />
  <img src="https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white" alt="Docker" />
</div>

<br />

Ce d√©p√¥t contient le syst√®me de centralisation et d'ingestion des logs de l'√©cosyst√®me. Il est con√ßu pour offrir de tr√®s hautes performances gr√¢ce √† la communication **gRPC** et un couplage asynchrone via **Apache Kafka**.

Il s'agit d'un projet **Gradle multi-modules** compos√© d'un contrat partag√©, d'un SDK (Starter Spring Boot) int√©grable dans n'importe quel microservice, et d'un serveur d'ingestion autonome.

## üìã Table des mati√®res
- [Architecture du projet](#-architecture-du-projet)
- [Pr√©requis](#-pr√©requis)
- [Installation et Build](#-installation-et-build)
- [Lancement de l'infrastructure (Docker & Kafka)](#-lancement-de-linfrastructure-docker--kafka)
- [Comment utiliser le SDK (Client)](#-comment-utiliser-le-sdk-client)
- [Tests](#-tests)

---

## üèó Architecture du projet

Le projet est divis√© en 3 modules distincts :

1. **`proto-schema`** : Contient le contrat d'interface (`logger.proto`) et g√©n√®re les classes Java/gRPC associ√©es.
2. **`log-sdk-starter`** : Une librairie (Spring Boot Starter) √† importer dans les autres microservices. Elle fournit l'annotation AOP `@Loggable` et un client gRPC pr√©-configur√© pour √©mettre les logs de mani√®re non bloquante.
3. **`log-ingestor`** : Le microservice serveur qui √©coute sur le port gRPC (`50051`), re√ßoit les flux de logs envoy√©s par les SDKs, et les pousse dans un topic **Kafka** (`app-logs`).

---

## üõ† Pr√©requis

Pour compiler et ex√©cuter ce projet localement :
- **Java 21** (JDK 21)
- **Docker & Docker Compose** (pour ex√©cuter Kafka et le serveur d'ingestion)

---

## üöÄ Installation et Build

### 1. Cloner le projet
```bash
git clone [https://github.com/wang-tu-94/ms.logs.producer.git](https://github.com/wang-tu-94/ms.logs.producer.git)
cd ms.logs.producer
```

### 2. Compiler le contrat gRPC (Protobuf)
Avant de lancer quoi que ce soit, il faut g√©n√©rer les classes issues du `.proto` :
```bash
./gradlew :proto-schema:build
```

### 3. Publier le SDK localement (Optionnel)
Si vous souhaitez tester le `log-sdk-starter` dans un autre projet local (ex: *product-trial-back*), publiez-le dans votre Maven local :
```bash
./gradlew publishToMavenLocal
```

---

## üê≥ Lancement de l'infrastructure (Docker & Kafka)

Le projet inclut un fichier `docker-compose-dev.yml` qui d√©ploie **Kafka (en mode KRaft)**, **Kafka UI** pour la visualisation, et le conteneur du **log-ingestor**.

```bash
# Lancer toute la stack en arri√®re-plan
docker-compose -f docker-compose-dev.yml up -d --build
```

- **Kafka UI** sera accessible sur : `http://localhost:9000`
- **Serveur gRPC (log-ingestor)** √©coutera sur : `localhost:50051`
- **Serveur HTTP (Actuator du log-ingestor)** √©coutera sur : `localhost:8
